/**
 * é«˜æ€§èƒ½æ¨¡æ¿ç¼“å­˜ç®¡ç†å™¨
 *
 * æä¾›é«˜æ•ˆçš„æ¨¡æ¿ç¼“å­˜æœºåˆ¶ï¼Œæ”¯æŒï¼š
 * - LRU ç¼“å­˜ç­–ç•¥
 * - é¢„åŠ è½½å’Œæ‡’åŠ è½½
 * - å†…å­˜ç®¡ç†
 * - ç¼“å­˜ç»Ÿè®¡
 * - æ€§èƒ½ç›‘æ§
 */

export interface CacheEntry<T = any> {
  /** ç¼“å­˜çš„å€¼ */
  value: T
  /** åˆ›å»ºæ—¶é—´ */
  createdAt: number
  /** æœ€åè®¿é—®æ—¶é—´ */
  lastAccessedAt: number
  /** è®¿é—®æ¬¡æ•° */
  accessCount: number
  /** ç¼“å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰ */
  size: number
  /** æ˜¯å¦ä¸ºé¢„åŠ è½½ */
  preloaded?: boolean
  /** ä¼˜å…ˆçº§ */
  priority?: number
  /** è¿‡æœŸæ—¶é—´ */
  expiresAt?: number
}

export interface CacheOptions {
  /** æœ€å¤§ç¼“å­˜æ¡ç›®æ•° */
  maxSize?: number
  /** æœ€å¤§å†…å­˜ä½¿ç”¨é‡ï¼ˆå­—èŠ‚ï¼‰ */
  maxMemory?: number
  /** ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ */
  ttl?: number
  /** æ˜¯å¦å¯ç”¨ç»Ÿè®¡ */
  enableStats?: boolean
  /** é¢„åŠ è½½ç­–ç•¥ */
  preloadStrategy?: 'aggressive' | 'conservative' | 'none'
  /** æ¸…ç†é—´éš”ï¼ˆæ¯«ç§’ï¼‰ */
  cleanupInterval?: number
}

export interface CacheStats {
  /** ç¼“å­˜å‘½ä¸­æ¬¡æ•° */
  hits: number
  /** ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•° */
  misses: number
  /** ç¼“å­˜å‘½ä¸­ç‡ */
  hitRate: number
  /** å½“å‰ç¼“å­˜æ¡ç›®æ•° */
  size: number
  /** å½“å‰å†…å­˜ä½¿ç”¨é‡ */
  memoryUsage: number
  /** æœ€å¤§å†…å­˜é™åˆ¶ */
  maxMemory: number
  /** å†…å­˜ä½¿ç”¨ç‡ */
  memoryUsageRate: number
  /** é¢„åŠ è½½å‘½ä¸­æ¬¡æ•° */
  preloadHits: number
  /** å¹³å‡è®¿é—®æ—¶é—´ */
  averageAccessTime: number
}

/**
 * é«˜æ€§èƒ½ LRU ç¼“å­˜ç®¡ç†å™¨
 */
export class PerformanceCache<T = any> {
  private cache = new Map<string, CacheEntry<T>>()
  private accessOrder: string[] = []
  private stats: CacheStats
  private options: Required<CacheOptions>
  private cleanupTimer?: NodeJS.Timeout
  private accessTimes: number[] = []

  constructor(options: CacheOptions = {}) {
    this.options = {
      maxSize: options.maxSize || 100,
      maxMemory: options.maxMemory || 50 * 1024 * 1024, // 50MB
      ttl: options.ttl || 30 * 60 * 1000, // 30åˆ†é’Ÿ
      enableStats: options.enableStats !== false,
      preloadStrategy: options.preloadStrategy || 'conservative',
      cleanupInterval: options.cleanupInterval || 5 * 60 * 1000, // 5åˆ†é’Ÿ
    }

    this.stats = {
      hits: 0,
      misses: 0,
      hitRate: 0,
      size: 0,
      memoryUsage: 0,
      maxMemory: this.options.maxMemory,
      memoryUsageRate: 0,
      preloadHits: 0,
      averageAccessTime: 0,
    }

    this.startCleanupTimer()
    console.log('ğŸš€ é«˜æ€§èƒ½ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ')
  }

  /**
   * è·å–ç¼“å­˜é¡¹
   */
  get(key: string): T | undefined {
    const startTime = performance.now()
    const entry = this.cache.get(key)

    if (!entry) {
      this.updateStats('miss')
      return undefined
    }

    // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
    if (this.isExpired(entry)) {
      this.delete(key)
      this.updateStats('miss')
      return undefined
    }

    // æ›´æ–°è®¿é—®ä¿¡æ¯
    entry.lastAccessedAt = Date.now()
    entry.accessCount++

    // æ›´æ–° LRU é¡ºåº
    this.updateAccessOrder(key)

    // è®°å½•è®¿é—®æ—¶é—´
    const accessTime = performance.now() - startTime
    this.recordAccessTime(accessTime)

    // æ›´æ–°ç»Ÿè®¡
    this.updateStats('hit', entry.preloaded)

    return entry.value
  }

  /**
   * è®¾ç½®ç¼“å­˜é¡¹
   */
  set(
    key: string,
    value: T,
    options?: {
      priority?: number
      preloaded?: boolean
      ttl?: number
    }
  ): void {
    const now = Date.now()
    const size = this.calculateSize(value)
    const ttl = options?.ttl || this.options.ttl

    const entry: CacheEntry<T> = {
      value,
      createdAt: now,
      lastAccessedAt: now,
      accessCount: 1,
      size,
      preloaded: options?.preloaded || false,
      priority: options?.priority || 1,
      expiresAt: now + ttl,
    }

    // æ£€æŸ¥å†…å­˜é™åˆ¶
    if (this.stats.memoryUsage + size > this.options.maxMemory) {
      this.evictByMemory(size)
    }

    // æ£€æŸ¥å¤§å°é™åˆ¶
    if (this.cache.size >= this.options.maxSize) {
      this.evictLRU()
    }

    this.cache.set(key, entry)
    this.updateAccessOrder(key)
    this.updateMemoryUsage()

    console.log(`ğŸ’¾ ç¼“å­˜é¡¹å·²è®¾ç½®: ${key} (${this.formatSize(size)})`)
  }

  /**
   * åˆ é™¤ç¼“å­˜é¡¹
   */
  delete(key: string): boolean {
    const entry = this.cache.get(key)
    if (!entry) return false

    this.cache.delete(key)
    this.removeFromAccessOrder(key)
    this.updateMemoryUsage()

    console.log(`ğŸ—‘ï¸ ç¼“å­˜é¡¹å·²åˆ é™¤: ${key}`)
    return true
  }

  /**
   * æ¸…ç©ºç¼“å­˜
   */
  clear(): void {
    this.cache.clear()
    this.accessOrder = []
    this.updateMemoryUsage()
    console.log('ğŸ§¹ ç¼“å­˜å·²æ¸…ç©º')
  }

  /**
   * é¢„åŠ è½½ç¼“å­˜é¡¹
   */
  async preload(key: string, loader: () => Promise<T>): Promise<void> {
    if (this.cache.has(key)) {
      console.log(`âš¡ ç¼“å­˜å‘½ä¸­ï¼Œè·³è¿‡é¢„åŠ è½½: ${key}`)
      return
    }

    try {
      console.log(`ğŸ”„ å¼€å§‹é¢„åŠ è½½: ${key}`)
      const value = await loader()
      this.set(key, value, { preloaded: true, priority: 2 })
      console.log(`âœ… é¢„åŠ è½½å®Œæˆ: ${key}`)
    } catch (error) {
      console.error(`âŒ é¢„åŠ è½½å¤±è´¥: ${key}`, error)
    }
  }

  /**
   * æ‰¹é‡é¢„åŠ è½½
   */
  async batchPreload(items: Array<{ key: string; loader: () => Promise<T> }>): Promise<void> {
    console.log(`ğŸš€ å¼€å§‹æ‰¹é‡é¢„åŠ è½½: ${items.length} é¡¹`)
    const startTime = performance.now()

    const promises = items.map(item => this.preload(item.key, item.loader))
    await Promise.allSettled(promises)

    const endTime = performance.now()
    console.log(`âœ… æ‰¹é‡é¢„åŠ è½½å®Œæˆï¼Œè€—æ—¶: ${Math.round(endTime - startTime)}ms`)
  }

  /**
   * è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
   */
  getStats(): CacheStats {
    this.updateStats()
    return { ...this.stats }
  }

  /**
   * è·å–ç¼“å­˜é”®åˆ—è¡¨
   */
  keys(): string[] {
    return Array.from(this.cache.keys())
  }

  /**
   * æ£€æŸ¥ç¼“å­˜é¡¹æ˜¯å¦å­˜åœ¨
   */
  has(key: string): boolean {
    const entry = this.cache.get(key)
    return entry ? !this.isExpired(entry) : false
  }

  /**
   * è·å–ç¼“å­˜å¤§å°
   */
  size(): number {
    return this.cache.size
  }

  /**
   * é”€æ¯ç¼“å­˜ç®¡ç†å™¨
   */
  destroy(): void {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer)
    }
    this.clear()
    console.log('ğŸ’¥ ç¼“å­˜ç®¡ç†å™¨å·²é”€æ¯')
  }

  // ç§æœ‰æ–¹æ³•

  private isExpired(entry: CacheEntry<T>): boolean {
    return entry.expiresAt ? Date.now() > entry.expiresAt : false
  }

  private updateAccessOrder(key: string): void {
    const index = this.accessOrder.indexOf(key)
    if (index > -1) {
      this.accessOrder.splice(index, 1)
    }
    this.accessOrder.push(key)
  }

  private removeFromAccessOrder(key: string): void {
    const index = this.accessOrder.indexOf(key)
    if (index > -1) {
      this.accessOrder.splice(index, 1)
    }
  }

  private evictLRU(): void {
    if (this.accessOrder.length === 0) return

    const keyToEvict = this.accessOrder[0]
    this.delete(keyToEvict)
    console.log(`ğŸ”„ LRU æ·˜æ±°: ${keyToEvict}`)
  }

  private evictByMemory(requiredSize: number): void {
    let freedMemory = 0
    const toEvict: string[] = []

    // æŒ‰ä¼˜å…ˆçº§å’Œè®¿é—®æ—¶é—´æ’åºï¼Œä¼˜å…ˆæ·˜æ±°ä½ä¼˜å…ˆçº§å’Œä¹…æœªè®¿é—®çš„é¡¹
    const sortedKeys = this.accessOrder.slice().sort((a, b) => {
      const entryA = this.cache.get(a)!
      const entryB = this.cache.get(b)!

      // ä¼˜å…ˆçº§ä½çš„å…ˆæ·˜æ±°
      if (entryA.priority !== entryB.priority) {
        return entryA.priority! - entryB.priority!
      }

      // è®¿é—®æ—¶é—´æ—©çš„å…ˆæ·˜æ±°
      return entryA.lastAccessedAt - entryB.lastAccessedAt
    })

    for (const key of sortedKeys) {
      const entry = this.cache.get(key)
      if (!entry) continue

      toEvict.push(key)
      freedMemory += entry.size

      if (freedMemory >= requiredSize) break
    }

    toEvict.forEach(key => this.delete(key))
    console.log(`ğŸ§¹ å†…å­˜æ¸…ç†: é‡Šæ”¾ ${this.formatSize(freedMemory)}ï¼Œæ·˜æ±° ${toEvict.length} é¡¹`)
  }

  private calculateSize(value: T): number {
    try {
      return new Blob([JSON.stringify(value)]).size
    } catch {
      return 1024 // é»˜è®¤ 1KB
    }
  }

  private updateMemoryUsage(): void {
    let totalSize = 0
    for (const entry of this.cache.values()) {
      totalSize += entry.size
    }
    this.stats.memoryUsage = totalSize
    this.stats.size = this.cache.size
    this.stats.memoryUsageRate = totalSize / this.options.maxMemory
  }

  private updateStats(type?: 'hit' | 'miss', isPreload?: boolean): void {
    if (!this.options.enableStats) return

    if (type === 'hit') {
      this.stats.hits++
      if (isPreload) {
        this.stats.preloadHits++
      }
    } else if (type === 'miss') {
      this.stats.misses++
    }

    const total = this.stats.hits + this.stats.misses
    this.stats.hitRate = total > 0 ? this.stats.hits / total : 0

    // æ›´æ–°å¹³å‡è®¿é—®æ—¶é—´
    if (this.accessTimes.length > 0) {
      this.stats.averageAccessTime = this.accessTimes.reduce((a, b) => a + b, 0) / this.accessTimes.length
    }
  }

  private recordAccessTime(time: number): void {
    this.accessTimes.push(time)
    // åªä¿ç•™æœ€è¿‘ 100 æ¬¡è®¿é—®æ—¶é—´
    if (this.accessTimes.length > 100) {
      this.accessTimes.shift()
    }
  }

  private startCleanupTimer(): void {
    this.cleanupTimer = setInterval(() => {
      this.cleanup()
    }, this.options.cleanupInterval)
  }

  private cleanup(): void {
    const now = Date.now()
    const expiredKeys: string[] = []

    for (const [key, entry] of this.cache.entries()) {
      if (this.isExpired(entry)) {
        expiredKeys.push(key)
      }
    }

    expiredKeys.forEach(key => this.delete(key))

    if (expiredKeys.length > 0) {
      console.log(`ğŸ§¹ å®šæœŸæ¸…ç†: ç§»é™¤ ${expiredKeys.length} ä¸ªè¿‡æœŸé¡¹`)
    }
  }

  private formatSize(bytes: number): string {
    const units = ['B', 'KB', 'MB', 'GB']
    let size = bytes
    let unitIndex = 0

    while (size >= 1024 && unitIndex < units.length - 1) {
      size /= 1024
      unitIndex++
    }

    return `${size.toFixed(1)}${units[unitIndex]}`
  }
}

/**
 * åˆ›å»ºé«˜æ€§èƒ½ç¼“å­˜å®ä¾‹
 */
export function createPerformanceCache<T = any>(options?: CacheOptions): PerformanceCache<T> {
  return new PerformanceCache<T>(options)
}
